{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af210936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/python/3.12.1/lib/python3.12/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pandas) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests) (2025.11.12)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: alpaca-py in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.43.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from alpaca-py) (1.1.2)\n",
      "Requirement already satisfied: pandas>=1.5.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from alpaca-py) (3.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from alpaca-py) (2.12.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.30.0 in /home/codespace/.local/lib/python3.12/site-packages (from alpaca-py) (2.32.5)\n",
      "Requirement already satisfied: sseclient-py<2.0.0,>=1.7.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from alpaca-py) (1.9.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from alpaca-py) (16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/codespace/.local/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py) (2025.11.12)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pandas>=1.5.3->alpaca-py) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas>=1.5.3->alpaca-py) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.3->alpaca-py) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pytz in /usr/local/python/3.12.1/lib/python3.12/site-packages (2025.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pytickersymbols in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.17.8)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from pytickersymbols) (4.14.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/codespace/.local/lib/python3.12/site-packages (from pytickersymbols) (2.32.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.0->pytickersymbols) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.0->pytickersymbols) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->pytickersymbols) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->pytickersymbols) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->pytickersymbols) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.31.0->pytickersymbols) (2025.11.12)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-23.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.1 kB)\n",
      "Downloading pyarrow-23.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (47.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-23.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install requests\n",
    "%pip install alpaca-py\n",
    "%pip install pytz\n",
    "%pip install pytickersymbols\n",
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f870bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['open', 'high', 'low', 'close', 'volume', 'trade_count', 'vwap'], dtype='str')\n",
      "                open           high            low          close  \\\n",
      "count  194786.000000  194786.000000  194786.000000  194786.000000   \n",
      "mean      169.172977     169.241115     169.103207     169.173106   \n",
      "std        24.338842      24.346925      24.331458      24.338446   \n",
      "min        95.090000      95.140100      95.040000      95.080000   \n",
      "25%       157.859900     157.909925     157.810000     157.858075   \n",
      "50%       178.050000     178.130000     177.980000     178.050000   \n",
      "75%       185.000000     185.060000     184.930000     185.000000   \n",
      "max       211.985000     212.189900     211.740000     211.980000   \n",
      "\n",
      "             volume    trade_count           vwap  \n",
      "count  1.947860e+05  194786.000000  194786.000000  \n",
      "mean   1.958244e+05    2221.902431     169.172825  \n",
      "std    6.613354e+05    3870.025792      24.339137  \n",
      "min    1.390000e+02       1.000000      95.087022  \n",
      "25%    5.241000e+03     102.000000     157.860477  \n",
      "50%    2.452950e+04     348.000000     178.048078  \n",
      "75%    2.578172e+05    2810.750000     184.993280  \n",
      "max    7.121155e+07  106824.000000     211.998038  \n",
      "               open          high           low         close        volume  \\\n",
      "count  83283.000000  83283.000000  83283.000000  83283.000000  8.328300e+04   \n",
      "mean     169.251598    169.352274    169.147737    169.249326  4.232918e+05   \n",
      "std       24.063288     24.076969     24.052209     24.062916  9.448835e+05   \n",
      "min       95.090000     95.140100     95.040000     95.080000  0.000000e+00   \n",
      "25%      158.245000    158.320000    158.157500    158.242500  1.913695e+05   \n",
      "50%      178.150000    178.260000    178.040000    178.154200  2.878000e+05   \n",
      "75%      185.155000    185.260000    185.040000    185.155000  4.588825e+05   \n",
      "max      211.985000    212.189900    211.740000    211.980000  7.121155e+07   \n",
      "\n",
      "         trade_count          vwap  \n",
      "count   80143.000000  80143.000000  \n",
      "mean     5040.548195    169.260523  \n",
      "std      4695.137509     24.209542  \n",
      "min        20.000000     95.087022  \n",
      "25%      2192.000000    158.239740  \n",
      "50%      3377.000000    178.146365  \n",
      "75%      6666.500000    184.998778  \n",
      "max    106824.000000    211.998038  \n"
     ]
    }
   ],
   "source": [
    "from alpaca.data.timeframe import TimeFrame\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data import StockHistoricalDataClient\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "stock_client = StockHistoricalDataClient(\"PKDBAP3S6DPDWEUTLD77R256C6\", \"DVKUFxa3UNtu4yJuWXFWyuzGAEaqCkSgZvJvgBsectr1\")\n",
    "\n",
    "def get_historical_data():\n",
    "    stock_client = StockHistoricalDataClient(\"PKDBAP3S6DPDWEUTLD77R256C6\", \"DVKUFxa3UNtu4yJuWXFWyuzGAEaqCkSgZvJvgBsectr1\")\n",
    "    formatted_request = StockBarsRequest(\n",
    "        symbol_or_symbols=[\"NVDA\"], # This could change right now it is a hardcoded value but in the future it could be dynamic\n",
    "        start=datetime(2025, 4, 18), # This could change right now it is a hardcoded value but in the future it could be dynamic \n",
    "        end=datetime(2026,2,12), # This could change right now it is a hardcoded value but in the future it could be dynamic \n",
    "        timeframe=TimeFrame.Minute\n",
    "    )\n",
    "    response = stock_client.get_stock_bars(formatted_request)\n",
    "    #print(response)\n",
    "    return response\n",
    "\n",
    "Stock_Data = get_historical_data()\n",
    "\n",
    "mydf = Stock_Data.df\n",
    "\n",
    "print(mydf.columns) # This is just to check what columns we have in the DataFrame it also is basically a test to make sure the above works\n",
    "print(mydf.describe())\n",
    "\n",
    "mydf = mydf.reset_index()\n",
    "mydf = mydf.set_index(\"timestamp\")\n",
    "\n",
    "# This just makes it so the timezone is the same timezone as us though it could change depending on what we want to do in the future\n",
    "mydf = mydf.tz_convert(\"US/Central\")\n",
    "mydf = mydf.between_time(\"08:30\", \"15:00\")\n",
    "mydf = mydf[mydf.index.dayofweek < 5]\n",
    "\n",
    "market_open = pd.to_datetime(\"08:30\").time()\n",
    "market_close = pd.to_datetime(\"15:00\").time()\n",
    "\n",
    "\n",
    "full_timeline = pd.date_range(start=mydf.index.min(),end=mydf.index.max(), freq=\"1min\", tz=\"US/Central\")\n",
    "full_timeline = full_timeline[(full_timeline.time >= market_open) & (full_timeline.time <= market_close) & (full_timeline.dayofweek < 5)]\n",
    "\n",
    "mydf = mydf.reindex(full_timeline)\n",
    "\n",
    "# This is basically the santization though unsure if this is how we want to handle it.\n",
    "# Right now this uses the last available data point to fill in the missing values for open, high, low, and close, and fills in missing volume with 0.\n",
    "\n",
    "# *********************** HAVE TO ASK *************************\n",
    "# Do we want to handle the missing data differently? \n",
    "\n",
    "mydf[['open', 'high', 'low', 'close']] = mydf[['open', 'high', 'low', 'close']].ffill()\n",
    "mydf['volume'] = mydf['volume'].fillna(0)\n",
    "\n",
    "\n",
    "print(mydf.describe())\n",
    "\n",
    "# ************************* SUMMARY *************************\n",
    "# So all in all the DataFrame is called mydf and it has the following columns: open, high, low, close, volume. \n",
    "# It is in Central Time Zone though could change depending on what we want to do\n",
    "# Also think this could all be converted to a function that takes in the symbol, start date, end date, and timezone as parameters and then returns the cleaned DataFrame. \n",
    "# Just not entirely sure what we want or how this is all going to be used in the future so I just left it as is for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91c41d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active NYSE assets: 2881\n",
      "Active NASDAQ assets: 5322\n"
     ]
    }
   ],
   "source": [
    "from alpaca.broker import client\n",
    "from alpaca.trading.requests import GetAssetsRequest\n",
    "\n",
    "#Note: I learned only AFTER writing this, you need seperate api keys for the broker client\n",
    "# Get those here: https://broker-app.alpaca.markets/dashboard\n",
    "\n",
    "broker_client = client.BrokerClient(\"CKZXMIOPRAG37W7T53KW5F2YOW\", \"8hA9KKQhF7ZWnFdb78Pb2dqenm6hBC1NUDqdUnHvzTH\")\n",
    "\n",
    "request_params = GetAssetsRequest(\n",
    "    status=\"active\",\n",
    "    asset_class=\"us_equity\",\n",
    "    exchange=\"NYSE\"\n",
    ")\n",
    "\n",
    "nyse_assets = broker_client.get_all_assets(request_params)\n",
    "nasdaq_assets = broker_client.get_all_assets(GetAssetsRequest(status=\"active\", asset_class=\"us_equity\", exchange=\"NASDAQ\"))\n",
    "\n",
    "print(f\"Active NYSE assets: {len(nyse_assets)}\")\n",
    "print(f\"Active NASDAQ assets: {len(nasdaq_assets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "217de6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8202 Count of symbols fetched from broker API\n"
     ]
    }
   ],
   "source": [
    "def fetch_symbols_from_response(nyse_assets, nasdaq_assets):\n",
    "    #This is called list comprehension\n",
    "    nyse_symbols = [asset.symbol for asset in nyse_assets if asset.status == \"active\" and asset.tradable]\n",
    "    nasdaq_symbols = [asset.symbol for asset in nasdaq_assets if asset.status == \"active\" and asset.tradable]\n",
    "    return nyse_symbols + nasdaq_symbols\n",
    "symbols_list = fetch_symbols_from_response(nyse_assets, nasdaq_assets)\n",
    "print(len(symbols_list), \"Count of symbols fetched from broker API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9488bb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1000 symbols by latest daily dollar volume:\n",
      "symbol\n",
      "QQQ     6.746866e+11\n",
      "NVDA    6.141162e+11\n",
      "TSLA    5.567444e+11\n",
      "MSFT    3.134278e+11\n",
      "MU      2.781284e+11\n",
      "            ...     \n",
      "CRWG    2.200888e+09\n",
      "FBIN    2.197632e+09\n",
      "ALC     2.195588e+09\n",
      "ZION    2.194076e+09\n",
      "EXEL    2.192365e+09\n",
      "Name: dollar_volume, Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def find_top_1000_assets(symbols_list, stock_client):\n",
    "    # This function will fetch the latest daily dollar volume for each symbol and return the top 1000 by that metric.\n",
    "    bars = stock_client.get_stock_bars(StockBarsRequest(\n",
    "        symbol_or_symbols=symbols_list,\n",
    "        timeframe=TimeFrame.Day,\n",
    "        start=datetime(2026, 1, 1),\n",
    "        end=datetime(2026, 2, 1)\n",
    "    ))\n",
    "    bars_df = bars.df\n",
    "    bars_df[\"dollar_volume\"] = bars_df[\"close\"] * bars_df[\"volume\"]\n",
    "    # Sort symbols by dollar volume and take top 1000\n",
    "    top_1000 = bars_df.groupby(\"symbol\")[\"dollar_volume\"].sum().nlargest(1000)\n",
    "    return top_1000\n",
    "\n",
    "top_1000_symbols = find_top_1000_assets(symbols_list, stock_client)\n",
    "print(\"Top 1000 symbols by latest daily dollar volume:\")\n",
    "print(top_1000_symbols)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8719b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyarrow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_stock_data\u001b[39m(ticker):\n\u001b[32m      8\u001b[39m     stock_client = StockHistoricalDataClient(\u001b[33m\"\u001b[39m\u001b[33mPKDBAP3S6DPDWEUTLD77R256C6\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDVKUFxa3UNtu4yJuWXFWyuzGAEaqCkSgZvJvgBsectr1\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyarrow'"
     ]
    }
   ],
   "source": [
    "import pyarrow\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_stock_data(ticker):\n",
    "    stock_client = StockHistoricalDataClient(\"PKDBAP3S6DPDWEUTLD77R256C6\", \"DVKUFxa3UNtu4yJuWXFWyuzGAEaqCkSgZvJvgBsectr1\")\n",
    "\n",
    "    def get_historical_data(ticker):\n",
    "        stock_client = StockHistoricalDataClient(\"PKDBAP3S6DPDWEUTLD77R256C6\", \"DVKUFxa3UNtu4yJuWXFWyuzGAEaqCkSgZvJvgBsectr1\")\n",
    "        formatted_request = StockBarsRequest(\n",
    "            symbol_or_symbols=[ticker], # This could change right now it is a hardcoded value but in the future it could be dynamic\n",
    "            start=datetime(2025, 4, 18), # This could change right now it is a hardcoded value but in the future it could be dynamic \n",
    "            end=datetime(2026,2,12), # This could change right now it is a hardcoded value but in the future it could be dynamic \n",
    "            timeframe=TimeFrame.Minute\n",
    "        )\n",
    "        response = stock_client.get_stock_bars(formatted_request)\n",
    "        #print(response)\n",
    "        return response\n",
    "\n",
    "    Stock_Data = get_historical_data()\n",
    "\n",
    "    mydf = Stock_Data.df\n",
    "\n",
    "    print(mydf.columns) # This is just to check what columns we have in the DataFrame it also is basically a test to make sure the above works\n",
    "    print(mydf.describe())\n",
    "\n",
    "    mydf = mydf.reset_index()\n",
    "    mydf = mydf.set_index(\"timestamp\")\n",
    "\n",
    "    mydf = mydf.tz_convert(\"US/Central\")\n",
    "    mydf = mydf.between_time(\"08:30\", \"15:00\")\n",
    "    mydf = mydf[mydf.index.dayofweek < 5]\n",
    "\n",
    "    market_open = pd.to_datetime(\"08:30\").time()\n",
    "    market_close = pd.to_datetime(\"15:00\").time()\n",
    "\n",
    "\n",
    "    full_timeline = pd.date_range(start=mydf.index.min(),end=mydf.index.max(), freq=\"1min\", tz=\"US/Central\")\n",
    "    full_timeline = full_timeline[(full_timeline.time >= market_open) & (full_timeline.time <= market_close) & (full_timeline.dayofweek < 5)]\n",
    "\n",
    "    mydf = mydf.reindex(full_timeline)\n",
    "\n",
    "    mydf[['open', 'high', 'low', 'close']] = mydf[['open', 'high', 'low', 'close']].ffill()\n",
    "    mydf['volume'] = mydf['volume'].fillna(0)\n",
    "\n",
    "\n",
    "    print(mydf.describe())\n",
    "    return mydf\n",
    "\n",
    "\n",
    "def convert_to_Dollar_bars(mydf):\n",
    "    current_dollar_value = 0\n",
    "    current_set = [] # my list of current rows I need for the dollar bar\n",
    "    final_set = [] # my final dollar bar data\n",
    "    \n",
    "    #print(temp_mydf['Close']*temp_mydf['Volume'])\n",
    "    #print()\n",
    "\n",
    "    for index, row in temp_mydf.iterrows():\n",
    "        #print(f\"{row['Close']} * {row['Volume']} \" )\n",
    "        dollar_tot = row['Close']*row['Volume']\n",
    "        current_dollar_value += dollar_tot\n",
    "        #print(current_dollar_value)\n",
    "        #now the goal is to populate the list with data\n",
    "        current_set.append(row)\n",
    "        #print(current_set)\n",
    "        print()\n",
    "        if current_dollar_value >= Strategist_Threshold:\n",
    "            \n",
    "            #new_df_dollar_bar = temp_mydf.copy()\n",
    "            new_df_dollar_bar = pd.DataFrame(current_set)\n",
    "            print(new_df_dollar_bar)\n",
    "            open_price = new_df_dollar_bar.iloc[0]['Close']\n",
    "            close_price = new_df_dollar_bar.iloc[-1]['Close']\n",
    "            high_price = new_df_dollar_bar.max()['Close']\n",
    "            low_price = new_df_dollar_bar.min()['Close']\n",
    "            final_set.append({\"Open\":open_price, \"High\":high_price, \n",
    "                            \"Low\":low_price, \"Close\":close_price,\n",
    "                            \"Dollar Volume\": current_dollar_value})\n",
    "            current_set = []\n",
    "            current_dollar_value = 0  # Note: AI recomends to do a substraction of the Strategist's data instead of setting all to 0\n",
    "    final_set_df = pd.DataFrame(final_set)\n",
    "    print(final_set_df)\n",
    "    return final_set_df\n",
    "\n",
    "\n",
    "\n",
    "def create_parquet_files(ticker):\n",
    "    tempdf = get_stock_data(ticker)\n",
    "    tempdf.to_parquet(output_filename, engine='pyarrow', compression='snappy')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5967ab77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active NYSE assets: 2883\n",
      "Active NASDAQ assets: 5333\n",
      "8214 Count of symbols fetched from broker API\n"
     ]
    },
    {
     "ename": "ArrowKeyError",
     "evalue": "A type extension with name pandas.period already defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArrowKeyError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 117\u001b[39m\n\u001b[32m    114\u001b[39m         df.to_parquet(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata/raw/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.parquet\u001b[39m\u001b[33m\"\u001b[39m, engine=\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m, compression=\u001b[33m'\u001b[39m\u001b[33msnappy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# This is commented out for now because it takes long to run as it builds the parquet files.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[43mcreate_parquet_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_1000_symbols\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;66;03m# This is just to check that we can read the parquet files we just created and that they look correct. We will delete this code later, it is just for testing purposes.\u001b[39;00m\n\u001b[32m    122\u001b[39m parquet_files = os.listdir(\u001b[33m\"\u001b[39m\u001b[33mdata/raw\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36mcreate_parquet_files\u001b[39m\u001b[34m(symbols_list)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m symbols_list:\n\u001b[32m    113\u001b[39m     df = get_stock_data(ticker)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/raw/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mticker\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpyarrow\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msnappy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/frame.py:3135\u001b[39m, in \u001b[36mDataFrame.to_parquet\u001b[39m\u001b[34m(self, path, engine, compression, index, partition_cols, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m   3032\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3033\u001b[39m \u001b[33;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[32m   3034\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3131\u001b[39m \u001b[33;03m>>> content = f.read()\u001b[39;00m\n\u001b[32m   3132\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3133\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[32m-> \u001b[39m\u001b[32m3135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3136\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3144\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3145\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/io/parquet.py:486\u001b[39m, in \u001b[36mto_parquet\u001b[39m\u001b[34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[39m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partition_cols, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    485\u001b[39m     partition_cols = [partition_cols]\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m path_or_buf: FilePath | WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] = io.BytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[32m    490\u001b[39m impl.write(\n\u001b[32m    491\u001b[39m     df,\n\u001b[32m    492\u001b[39m     path_or_buf,\n\u001b[32m   (...)\u001b[39m\u001b[32m    498\u001b[39m     **kwargs,\n\u001b[32m    499\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/io/parquet.py:79\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to find a usable engine; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtried using: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPyArrowImpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m FastParquetImpl()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/io/parquet.py:170\u001b[39m, in \u001b[36mPyArrowImpl.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparquet\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# import utils to register the pyarrow extension types\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrays\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marrow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension_types\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[38;5;28mself\u001b[39m.api = pyarrow\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/core/arrays/arrow/extension_types.py:59\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# register the type with a dummy instance\u001b[39;00m\n\u001b[32m     58\u001b[39m _period_type = ArrowPeriodType(\u001b[33m\"\u001b[39m\u001b[33mD\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43mpyarrow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_extension_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_period_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mArrowIntervalType\u001b[39;00m(pyarrow.ExtensionType):\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, subtype, closed: IntervalClosedType) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     64\u001b[39m         \u001b[38;5;66;03m# attributes need to be set first before calling\u001b[39;00m\n\u001b[32m     65\u001b[39m         \u001b[38;5;66;03m# super init (as that calls serialize)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pyarrow/types.pxi:2226\u001b[39m, in \u001b[36mpyarrow.lib.register_extension_type\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001b[39m, in \u001b[36mpyarrow.lib.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mArrowKeyError\u001b[39m: A type extension with name pandas.period already defined"
     ]
    }
   ],
   "source": [
    "from alpaca.data.timeframe import TimeFrame\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data import StockHistoricalDataClient\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow\n",
    "\n",
    "stock_client = StockHistoricalDataClient(\"PKDBAP3S6DPDWEUTLD77R256C6\", \"DVKUFxa3UNtu4yJuWXFWyuzGAEaqCkSgZvJvgBsectr1\")\n",
    "\n",
    "\n",
    "from alpaca.broker import client\n",
    "from alpaca.trading.requests import GetAssetsRequest\n",
    "\n",
    "#Note: I learned only AFTER writing this, you need seperate api keys for the broker client\n",
    "# Get those here: https://broker-app.alpaca.markets/dashboard\n",
    "\n",
    "broker_client = client.BrokerClient(\"CKZXMIOPRAG37W7T53KW5F2YOW\", \"8hA9KKQhF7ZWnFdb78Pb2dqenm6hBC1NUDqdUnHvzTH\")\n",
    "\n",
    "request_params = GetAssetsRequest(\n",
    "    status=\"active\",\n",
    "    asset_class=\"us_equity\",\n",
    "    exchange=\"NYSE\"\n",
    ")\n",
    "\n",
    "nyse_assets = broker_client.get_all_assets(request_params)\n",
    "nasdaq_assets = broker_client.get_all_assets(GetAssetsRequest(status=\"active\", asset_class=\"us_equity\", exchange=\"NASDAQ\"))\n",
    "\n",
    "print(f\"Active NYSE assets: {len(nyse_assets)}\")\n",
    "print(f\"Active NASDAQ assets: {len(nasdaq_assets)}\")\n",
    "\n",
    "def fetch_symbols_from_response(nyse_assets, nasdaq_assets):\n",
    "    #This is called list comprehension\n",
    "    nyse_symbols = [asset.symbol for asset in nyse_assets if asset.status == \"active\" and asset.tradable]\n",
    "    nasdaq_symbols = [asset.symbol for asset in nasdaq_assets if asset.status == \"active\" and asset.tradable]\n",
    "    return nyse_symbols + nasdaq_symbols\n",
    "symbols_list = fetch_symbols_from_response(nyse_assets, nasdaq_assets)\n",
    "print(len(symbols_list), \"Count of symbols fetched from broker API\")\n",
    "\n",
    "\n",
    "# This is what I think we have to mess around with to get our top 1000 tickers \n",
    "\n",
    "def find_top_1000_assets(symbols_list, stock_client):\n",
    "    # This function will fetch the latest daily dollar volume for each symbol and return the top 1000 by that metric.\n",
    "    bars = stock_client.get_stock_bars(StockBarsRequest(\n",
    "        symbol_or_symbols=symbols_list,\n",
    "        timeframe=TimeFrame.Day,\n",
    "        start=datetime(2026, 1, 1),\n",
    "        end=datetime(2026, 2, 1)\n",
    "    ))\n",
    "    bars_df = bars.df\n",
    "    bars_df[\"dollar_volume\"] = bars_df[\"close\"] * bars_df[\"volume\"]\n",
    "    # Sort symbols by dollar volume and take top 1000\n",
    "    top_1000 = bars_df.groupby(\"symbol\")[\"dollar_volume\"].sum().nlargest(1000)\n",
    "    return top_1000\n",
    "\n",
    "top_1000_symbols = find_top_1000_assets(symbols_list, stock_client)\n",
    "#print(\"Top 1000 symbols by latest daily dollar volume:\")\n",
    "#print(top_1000_symbols)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_stock_data(ticker):\n",
    "\n",
    "    def get_historical_data(ticker):\n",
    "        stock_client = StockHistoricalDataClient(\"PKDBAP3S6DPDWEUTLD77R256C6\", \"DVKUFxa3UNtu4yJuWXFWyuzGAEaqCkSgZvJvgBsectr1\")\n",
    "        formatted_request = StockBarsRequest(\n",
    "            symbol_or_symbols=[ticker], # This could change right now it is a hardcoded value but in the future it could be dynamic\n",
    "            start=datetime(2025, 4, 18), # This could change right now it is a hardcoded value but in the future it could be dynamic \n",
    "            end=datetime(2026,2,12), # This could change right now it is a hardcoded value but in the future it could be dynamic \n",
    "            timeframe=TimeFrame.Minute\n",
    "        )\n",
    "        response = stock_client.get_stock_bars(formatted_request)\n",
    "        #print(response)\n",
    "        return response\n",
    "\n",
    "\n",
    "    mydf = get_historical_data(ticker).df\n",
    "\n",
    "    #print(mydf.columns) # This is just to check what columns we have in the DataFrame it also is basically a test to make sure the above works\n",
    "    #print(mydf.describe())\n",
    "\n",
    "    mydf = mydf.reset_index()\n",
    "    mydf = mydf.set_index(\"timestamp\")\n",
    "\n",
    "    mydf = mydf.tz_convert(\"US/Central\")\n",
    "    mydf = mydf.between_time(\"08:30\", \"15:00\")\n",
    "    mydf = mydf[mydf.index.dayofweek < 5]\n",
    "\n",
    "    market_open = pd.to_datetime(\"08:30\").time()\n",
    "    market_close = pd.to_datetime(\"15:00\").time()\n",
    "\n",
    "\n",
    "    full_timeline = pd.date_range(start=mydf.index.min(),end=mydf.index.max(), freq=\"1min\", tz=\"US/Central\")\n",
    "    full_timeline = full_timeline[(full_timeline.time >= market_open) & (full_timeline.time <= market_close) & (full_timeline.dayofweek < 5)]\n",
    "\n",
    "    mydf = mydf.reindex(full_timeline)\n",
    "\n",
    "    mydf[['open', 'high', 'low', 'close']] = mydf[['open', 'high', 'low', 'close']].ffill()\n",
    "    mydf['volume'] = mydf['volume'].fillna(0)\n",
    "\n",
    "\n",
    "    #print(mydf.describe())\n",
    "    return mydf\n",
    "\n",
    "def create_parquet_files(symbols_list):\n",
    "    os.makedirs(\"data/raw\", exist_ok=True)\n",
    "    \n",
    "    for ticker in symbols_list:\n",
    "        df = get_stock_data(ticker)\n",
    "        df.to_parquet(f\"data/raw/{ticker}.parquet\", engine='pyarrow', compression='snappy')\n",
    "\n",
    "# This is commented out for now because it takes long to run as it builds the parquet files.\n",
    "create_parquet_files(top_1000_symbols.index.tolist())\n",
    "\n",
    "\n",
    "# This is just to check that we can read the parquet files we just created and that they look correct. We will delete this code later, it is just for testing purposes.\n",
    "\n",
    "parquet_files = os.listdir(\"data/raw\")\n",
    "\n",
    "for file in parquet_files:\n",
    "    df = pd.read_parquet(f\"data/raw/{file}\", engine=\"pyarrow\")\n",
    "    ticker = file.replace(\".parquet\", \"\")\n",
    "    print(f\"{ticker} has {len(df)} rows of data\")\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
